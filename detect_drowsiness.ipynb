{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUw/fv+UVM2fwdhMd8CEZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanishingne/Driver-drowsiness-Detection/blob/master/detect_drowsiness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Implementing Driver Drowsiness Detection algorithm using OpenCV, dlib, and Python:*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jtVQfFkFYZGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Importing the necessary packages:\n",
        "\n"
      ],
      "metadata": {
        "id": "rqcu73wwfZll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade playsound\n",
        "from scipy.spatial import distance as dist\n",
        "import imutils\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "from threading import Thread\n",
        "from playsound import playsound\n",
        "import dlib\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import cv2\n",
        "import argparse"
      ],
      "metadata": {
        "id": "679HIBw1XfZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **SciPy**: We’ll need the SciPy package so we can compute the Euclidean distance between facial landmarks points in the Eye Aspect Ratio calculation.\n",
        "*   **imutils**: We’ll also use the imutils package, a series of computer vision and image processing functions to make working with OpenCV easier.\n",
        "* **Thread**: We'll import the Thread class so we can play our alarm in a separate thread from the main thread to ensure our script doesn’t pause execution while the alarm sounds.\n",
        "* **playsound**: We'll need the playsound library to play simple sounds like our MP3 alarm.\n",
        "* **dlib**: To detect and localize facial landmarks we’ll need the dlib library.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wa7gjdnyZp6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "2. Defining the sound_alarm function, which accepts a path to an audio file on the disk and then play  the sound:"
      ],
      "metadata": {
        "id": "XnhV5aHsfBRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sound_alarm(path):\n",
        "  # play an alarm sound\n",
        "  playsound.playsound(path)"
      ],
      "metadata": {
        "id": "NngNpCCKZ4jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "3. Defining the `eye_aspect_ratio` function which is used to compute the ratio of distances between the vertical eye landmarks and the distances between the horizontal eye landmarks:"
      ],
      "metadata": {
        "id": "4-etGYbef7Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eye_aspect_ratio(eye):\n",
        "  # compute the Euclidean distances between the two sets of vertical eye lankmark (x,y) coordinates:\n",
        "  A = dist.euclidean(eye[1], eye[5])\n",
        "  B = dist.euclidean(eye[2], eye[4])\n",
        "\n",
        "  # compute the Euclidean distances between the two sets of horizontal eye lankmark (x,y) coordinates:\n",
        "  C = dist.euclidean(eye[0], eye[3])\n",
        "\n",
        "  # compute the Eye-Aspect-Ratio:\n",
        "  ear = (A+B) / (2.0 * C)\n",
        "\n",
        "  # return the E.A.R:\n",
        "  return ear"
      ],
      "metadata": {
        "id": "Qn_1lEG2fy2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The EAR will be approximately constant when the eye is open, and when the eye is closed. However, the ratio will be much smaller than the ratio when the eye is open.\n",
        "* During a blink, the value will rapidly decrease towawrds zero.\n",
        "(Ref: Soukupová and Čech’s 2016 paper, [Real-Time Eye Blink Detection using Facial Landmarks](http://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf))\n",
        "\n",
        "* In our drowsiness detector case, we’ll be monitoring the eye aspect ratio to see if the value *falls* but does *not increase again*, thus implying that the person has closed their eyes.\n"
      ],
      "metadata": {
        "id": "0y12TedkmSfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "4. constructing the argument parser and parsing the arguments:"
      ],
      "metadata": {
        "id": "QZ8HR12hCiyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-p\", \"--shape-predictor\", required=True, help=\"path to facial landmark predictor\")\n",
        "ap.add_argument(\"-a\", \"--alarm\", type=str, default=\"\", help=\"path alarm .WAV file\")\n",
        "ap.add_argument(\"-w\", \"--webcam\", type=int, default=0, help=\"index of webcam on system\")\n",
        "args = vars(ap.parse_args())"
      ],
      "metadata": {
        "id": "J7SP3Y8xCKgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `--shape-predictor` : This is the path to dlib’s pre-trained facial landmark detector.\n",
        "* `--alarm` : Here you can optionally specify the path to an input audio file to be used as an alarm.\n",
        "* `--webcam` : This integer controls the index of your built-in webcam/USB camera."
      ],
      "metadata": {
        "id": "DjtXjDqfXFJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "5. Defining constants:"
      ],
      "metadata": {
        "id": "RRakGmLcdiXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the threshold for the EAR, indicating a \"blink\"\n",
        "EYE_AR_THRESH = 0.3\n",
        "\n",
        "# initialize the threshold for the number of consecutive frames to set off the alarm\n",
        "EYE_AR_CONSEC_FRAMES = 48\n",
        "\n",
        "# initialize the frame counter\n",
        "COUNTER = 0\n",
        "\n",
        "# initialize a boolean used to indicate if the alarm is going off\n",
        "ALARM_ON = False"
      ],
      "metadata": {
        "id": "V87g0mjTbata"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `EYE_AR_THRESH`: If the eye aspect ratio falls below this threshold, we’ll start counting the number of frames the person has closed their eyes for.\n",
        "- `EYE_AR_CONSEC_FRAMES`: If the number of frames the person has closed their eyes in exceeds EYE_AR_CONSEC_FRAMES, we’ll sound an alarm.\n",
        "- `COUNTER`: COUNTER defines the total number of consecutive frames where the eye aspect ratio is below EYE_AR_THRESH.\n",
        "- `ALARM_ON`: We'll update the boolean ALARM_ON if COUNTER exceeds EYE_AR_CONSEC_FRAMES."
      ],
      "metadata": {
        "id": "XvF3NVWAgc1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "6. Instantiate dlib's Histogram of Oriented Gradient-based face detector, along with Facial Landmark Predictor:"
      ],
      "metadata": {
        "id": "RUQOf5CPircV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading facial landmark predictor...\")\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(args[\"shape_predictor\"])"
      ],
      "metadata": {
        "id": "UmVZhrFiiU-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CHF3S_eskHDr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kSxKDg4vkGXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}